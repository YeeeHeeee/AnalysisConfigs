{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coffea.util as cu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/vols/cms/yhe4823/TopSBI/Functions')\n",
    "from OpenFiles import extract_dataframes\n",
    "from Plotting import correction_plot, inital_distributions_plot, stacked_hist, heat_map, comparison_plot, heat_map1, eff_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=cu.load(\"/vols/cms/yhe4823/TopSBI/Resolved/output_run2/output_all.coffea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables are:  dict_keys(['sum_genweights', 'sum_signOf_genweights', 'sumw', 'sumw2', 'cutflow', 'variables', 'columns', 'processing_metadata', 'datasets_metadata'])\n",
      "Channels are: dict_keys(['TTToHadronic', 'TTTo2L2Nu', 'TTToSemiLeptonic'])\n",
      "Processing datasets: TTToHadronic\n",
      "  TTToHadronic_2018\n",
      "    baseline\n",
      "  TTToHadronic_2017\n",
      "    baseline\n",
      "  TTToHadronic_2016_PostVFP\n",
      "    baseline\n",
      "  TTToHadronic_2016_PreVFP\n",
      "    baseline\n",
      "Processing datasets: TTTo2L2Nu\n",
      "  TTTo2L2Nu_2018\n",
      "    baseline\n",
      "  TTTo2L2Nu_2017\n",
      "    baseline\n",
      "  TTTo2L2Nu_2016_PostVFP\n",
      "    baseline\n",
      "  TTTo2L2Nu_2016_PreVFP\n",
      "    baseline\n",
      "Processing datasets: TTToSemiLeptonic\n",
      "  TTToSemiLeptonic_2018\n",
      "    baseline\n",
      "  TTToSemiLeptonic_2017\n",
      "    baseline\n",
      "  TTToSemiLeptonic_2016_PostVFP\n",
      "    baseline\n",
      "  TTToSemiLeptonic_2016_PreVFP\n",
      "    baseline\n"
     ]
    }
   ],
   "source": [
    "df, df_dict = extract_dataframes(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hadronic = df_dict.get(\"TTToHadronic_TTToHadronic_2018_baseline\", None)\n",
    "df_semileptonic = df_dict.get(\"TTToSemiLeptonic_TTToSemiLeptonic_2018_baseline\", None)\n",
    "df_leptonic = df_dict.get(\"TTTo2L2Nu_TTTo2L2Nu_2018_baseline\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_df_for_dataset(df_dict, dataset_name):\n",
    "    # Find all keys that start with the dataset_name\n",
    "    dataset_keys = [key for key in df_dict.keys() if key.startswith(dataset_name)]\n",
    "\n",
    "    # Initialize a list to store DataFrames for the dataset\n",
    "    df_list = []\n",
    "\n",
    "    # Loop through the keys and get the corresponding DataFrame\n",
    "    for key in dataset_keys:\n",
    "        df = df_dict.get(key, None)\n",
    "        if df is not None:\n",
    "            df_list.append(df)\n",
    "    \n",
    "    # Combine the DataFrames for the dataset\n",
    "    if df_list:\n",
    "        return pd.concat(df_list, ignore_index=True)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Use this function to get the combined DataFrame for TTToHadronic\n",
    "df_hadronic = get_combined_df_for_dataset(df_dict, \"TTToHadronic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weight', 'MET_pt', 'MET_phi', 'MET_fiducialGenPhi',\n",
       "       'MET_fiducialGenPt', 'Genjj_s_pt', 'Genjj_s_eta', 'Genjj_s_phi',\n",
       "       'Genjj_s_mass', 'Genbjj_deltaR_s_pt', 'Genbjj_deltaR_s_eta',\n",
       "       'Genbjj_deltaR_s_phi', 'Genbjj_deltaR_s_mass', 'Genbjj_deltaM_s_pt',\n",
       "       'Genbjj_deltaM_s_eta', 'Genbjj_deltaM_s_phi', 'Genbjj_deltaM_s_mass',\n",
       "       'jj_s_pt', 'jj_s_eta', 'jj_s_phi', 'jj_s_mass', 'bjj_deltaR_s_pt',\n",
       "       'bjj_deltaR_s_eta', 'bjj_deltaR_s_phi', 'bjj_deltaR_s_mass',\n",
       "       'bjj_deltaM_s_pt', 'bjj_deltaM_s_eta', 'bjj_deltaM_s_phi',\n",
       "       'bjj_deltaM_s_mass', 'Matchedjj_s_pt', 'Matchedjj_s_eta',\n",
       "       'Matchedjj_s_phi', 'Matchedjj_s_mass', 'Matchedbjj_deltaR_s_pt',\n",
       "       'Matchedbjj_deltaR_s_eta', 'Matchedbjj_deltaR_s_phi',\n",
       "       'Matchedbjj_deltaR_s_mass', 'Matchedbjj_deltaM_s_pt',\n",
       "       'Matchedbjj_deltaM_s_eta', 'Matchedbjj_deltaM_s_phi',\n",
       "       'Matchedbjj_deltaM_s_mass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hadronic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_years(df_dict):\n",
    "    # Initialize a dictionary to store combined DataFrames for each dataset\n",
    "    df_combined = {}\n",
    "\n",
    "    # Loop through all dataset keys in df_dict\n",
    "    for dataset_key in df_dict.keys():\n",
    "        parts = dataset_key.split('_')\n",
    "        dataset_name = '_'.join(parts[:-2])\n",
    "        \n",
    "        if dataset_name not in df_combined:\n",
    "            df_combined[dataset_name] = []\n",
    "        \n",
    "        df_combined[dataset_name].append(df_dict[dataset_key])\n",
    "\n",
    "    # Combine the DataFrames for each dataset\n",
    "    for dataset_name in df_combined:\n",
    "        print(f\"Combining data for {dataset_name}\")\n",
    "        print(f\"Number of DataFrames for {dataset_name}: {len(df_combined[dataset_name])}\")\n",
    "        df_combined[dataset_name] = pd.concat(df_combined[dataset_name], ignore_index=True)\n",
    "\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data for TTToHadronic_TTToHadronic\n",
      "Number of DataFrames for TTToHadronic_TTToHadronic: 2\n",
      "Combining data for TTToHadronic_TTToHadronic_2016\n",
      "Number of DataFrames for TTToHadronic_TTToHadronic_2016: 2\n",
      "Combining data for TTTo2L2Nu_TTTo2L2Nu\n",
      "Number of DataFrames for TTTo2L2Nu_TTTo2L2Nu: 2\n",
      "Combining data for TTTo2L2Nu_TTTo2L2Nu_2016\n",
      "Number of DataFrames for TTTo2L2Nu_TTTo2L2Nu_2016: 2\n",
      "Combining data for TTToSemiLeptonic_TTToSemiLeptonic\n",
      "Number of DataFrames for TTToSemiLeptonic_TTToSemiLeptonic: 2\n",
      "Combining data for TTToSemiLeptonic_TTToSemiLeptonic_2016\n",
      "Number of DataFrames for TTToSemiLeptonic_TTToSemiLeptonic_2016: 2\n"
     ]
    }
   ],
   "source": [
    "# Example: Combine the data from all available years\n",
    "df_combined = combine_years(df_dict)\n",
    "\n",
    "# Access the combined DataFrames for each dataset (e.g., 'TTToHadronic')\n",
    "df_hadronic = df_combined.get('TTToHadronic', None)\n",
    "df_semileptonic = df_combined.get('TTToSemiLeptonic', None)\n",
    "df_leptonic = df_combined.get('TTTo2L2Nu', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semileptonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hadronic = df_dict.get(\"TTToHadronic_TTToHadronic_2018_baseline\", None)\n",
    "df_semileptonic = df_dict.get(\"TTToSemiLeptonic_TTToSemiLeptonic_2018_baseline\", None)\n",
    "df_leptonic = df_dict.get(\"TTTo2L2Nu_TTTo2L2Nu_2018_baseline\", None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PC",
   "language": "python",
   "name": "clean_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
